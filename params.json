{"name":"Yag.js","tagline":"Yagnus Javascript Libraries","body":"Yagnus.js is a collection of classes that can be used to calculate statistics in browser, on servers or inside mongodb.\r\n\r\nDescriptive Statistics\r\n======================\r\n[Descriptive statistics](http://en.wikipedia.org/wiki/Descriptive_statistics) are numbers that we calculate to describe a large amount of data we have seen. The most important statistics are: [mean](http://en.wikipedia.org/wiki/Arithmetic_mean), [variance](http://en.wikipedia.org/wiki/Variance), [skewness](http://en.wikipedia.org/wiki/Skewness) and [kurtosis](http://en.wikipedia.org/wiki/Kurtosis), and [covariance](http://en.wikipedia.org/wiki/Covariance_matrix) for multivariate situations. Additionally, sometimes, one just wants to count things, such as number of times a word appear in a text. In the case of counting, we have created a [counting contingency table](http://en.wikipedia.org/wiki/Contingency_table) which can count one things or analyze cooccurance of multiple discrete variables.\r\n\r\nYagnus implements gathering of these statistics without storing all the data. At time of observing each data point, a constant-time update is performed. At the completion of the calculation, one may chose to call a calc() method to remove machinery for calculating data. After calc is run, the object can no longer be updated or merged with other aggregator.\r\n\r\nBasic descriptive statistics are not order sensitve so any permutation of the same set of data points will result in the identical statistics. This means that if we have two collection of statistics:\r\n\r\n    var statA = oy.UVar(); //for exampmle intialize a univariate statistics collector\r\n\r\n    //followed by some efforts of data gethering\r\n\t statA.inc(1);\r\n\r\n    var statB =oy.UVar();\r\n\t //followed by some separate effort of data gathering\r\n\t statB.inc(5);\r\n\r\n    //This followin operation adds all of the datapoints we observed in statB to statA as if we observed them directly using statA\r\n\t statA.inc(statB);\r\n\t var results=statA.calc();\r\n\r\n    //prints 3\r\n\t console.log(results.average);\r\n    //prints 2\r\n\t console.log(results.count);\r\n    \r\nUnivariate Statistics\r\n---------------------\r\nYagnus lib calculates sum, count, average, variance, skewness, kurtosis, min and max. To start calculating univariate stats call either the shorthand constructor or the constructor long form:\r\n\r\n    var stat = oy.UVar();\r\n    var stat = org.yagnus.stats.initUnivariateSummaryStatistics();\r\n\r\nTo add a number use the inc() method:\r\n\r\n    stat.inc(1);\r\n    stat.inc(3.1415);\r\n\r\nAdd a bunch of numbers all at once:\r\n\r\n    stat.inc(1,2,3,4,5,6,7);\r\n\r\nToo merge in a second univeriate stat use \"inc()\"\r\n    stat.inc(stat2);\r\n\r\nWhen all the data is gathered and frozen from a call to \"calc()\"\r\n\r\n    var results=stat.calc();\r\n\r\nAt this point stat can no longer b updated or merged but you can get results from the object:\r\n\r\n\tresults.sum;\r\n\tresults.count;\r\n\tresults.min;\r\n\tresults.max;\r\n\tresults.average;   //if it exists, otherwise null\r\n\tresults.variance;  //if it exists, otherwise null\r\n\tresults.standardDeviation;//if it exists, otherwise null\r\n\tresults.skew;      //if it exists, otherwise null\r\n\tresults.kurtosis;  //if it exists, otherwise null\r\n\tresults.bad;//contains the number of nan, infinity, or non-numerical strings passed to inc and excluded from above calculations\r\n\r\nFor those who are curious, the object from instantiation to calc() contains something close to the iminimum sufficient statistics to calculate the promised final statistics. Therefore storing the object means storing enough information to compute them merge with another set of these minimum sufficient statistics to form a larger aggregate. For compatibility with external systems, a method called \"getMSS()\" allows you retrieve a javascript object containing just these minimum sufficient statistics without the methods:\r\n\r\n    var stats = oy.UVar();\r\n    stats.getMss();\r\n    {\r\n    \t\"bad\" : 0,\r\n    \t\"c\" : 0,\r\n    \t\"s\" : 0,\r\n    \t\"ss\" : 0,\r\n    \t\"sss\" : 0,\r\n    \t\"ssss\" : 0,\r\n    \t\"min\" : 9007199254740992,\r\n    \t\"max\" : -9007199254740992,\r\n    \t\"mmbuffer\" : null,\r\n    \t\"mmind\" : false\r\n    },\r\n\r\nUnivariate Order Statistics\r\n----------------------------\r\nA separate set of algorithms are implemented to calculate median and order statistics that were not included in Univariate Stats above(namely, min&max). The class org.yagnus.stats.Median implements the [median-of-median algorithm known as BFPRT which are the initials of it's inventor Blum, Floyd, Pratt, Rivest, Tarjan](http://scholar.google.com/scholar?q=Blum+Floyd+Pratt+Rivest+Tarjan).\r\n\r\n    var m=org.yagnus.stats.initMedian();\r\n    var m2=oy.UMedian();\r\n    m.inc(1);m.inc(2);//etc...\r\n    m2.inc(100);m2.inc(1000000);//...\r\n    m.inc(m2);\r\n    m.calc();\r\n    m.median;\r\n\r\n\r\nMultivariate Statistics\r\n-----------------------\r\nMultivariate stats collector must be constructed with the number of variables we plan to observe.\r\n\r\n    var ms = oy.MVar(3);\r\n    var ms = org.yagnus.stats.initMultivariateSummaryStatistics(3);\r\n\r\nObserved data points must be entered separately using \"inc()\" with each parameter corresponding to the variable.\r\n\r\n    ms.inc(1,1,1);\r\n    ms.inc(2,2,2);\r\n    ms.inc(3,3,3);\r\n\r\nadd stats from another set of observation:\r\n\r\n\tms.inc(ms2);\r\n\r\nfinalize using \"calc()\"\r\n\r\n    ms.calc();\r\n\r\n\r\nthe resulting object contains univariate stats for each of the variables. these univariate stats are also calc()'ed when the multivariate aggregator is calc()'ed\r\n\r\n    ms.univariates[0].sum;\r\n    ms.univariates[1].variance;\r\n\r\nto get the covariance of two variables call \"getCovariance()\":\r\n\r\n    ms.getCovariance(0,1); //notice the variables uses 0-based  index\r\n    ms.getCovariance(0,2); //notice the variables uses 0-based  index\r\n\r\nThis object can also calculate the [//Pearson's Product-moment Correlation Coefficient](http://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient), again using 0-based index to refer to variables:\r\n\r\n    ms.getPPMCC(0,1);\r\n\r\nNote, all operations are constant-time wrt data count.\r\n\r\n\r\nDiscrete Multivariate Statistics\r\n-----------------------\r\nConstruction must specify dimensionality:\r\n\r\n    var ds = oy.DVar(3);\r\n    var ds = oy.Counter(3);\r\n    var ds = org.yagnus.stats.initDiscreteSummaryStatistics(3);\r\n\r\nObserve things:\r\n\r\n    ds.inc('a','b','c');\r\n\r\nAs with Univariate and Multivariate cases, the observed item must be fully observed or else the result will be undefined. \r\n \r\nMerge observations\r\n\r\n    ds.inc(ds2);\r\n\r\nFinalize:\r\n\r\n    ds.calc();\r\n\r\nGet cell counts:\r\n\r\n    ds.getCount('a','b','c');\r\n\r\nGet marginal count:\r\n\r\n    ds.getCount('a','b'); // number of times we saw 'a,b' followed by any third value.\r\n    ds.getCount(null,'b','c'); // number of times we saw 'b,c' following any first value.\r\n\r\nThe most frequent usecase will be to count things of just one type:\r\n\r\n\tvar ds = oy.Counter(1);\r\n   for(var i=0;i<100;++i)ds.inc('a');\r\n\tds.calc();\r\n   ds.getCount('a');//100 as expected\r\n\r\nOne can also ask the counter for all cells. The result is an associative array having each non-empty cell as value and the the full path to that cell as the key.\r\n\tvar ds = oy.Counter();\r\n   for(var i=0;i<100;++i)ds.inc('a');\r\n   for(var i=0;i<400;++i)ds.inc('b');\r\n\tds.calc();\r\n   ds.getAllCells(); //{ \"a\" : 100, \"b\" : 400 }\r\n\r\nHigher-dimensional counter:\r\n\tvar ds = oy.Counter(3);\r\n   ds.inc('a','b','c');\r\n   ds.inc('a','b','c');\r\n   ds.inc('d','e','f');\r\n\tds.calc();\r\n   ds.getAllCells(); //{ \"a,b,c\" : 2, \"d,e,f\" : 1 }\r\n\r\n\r\nSampling\r\n======================\r\nUniform Probability Sampling\r\n----------------------------\r\nMost distributed samplers implements sampling without replacement. Since it is relatively difficult to do it with replacement when the distribution (or possibly the population size) is unknown. Therefore these samplers are without replacement samplers without additional specification.\r\n\r\nThe simplest sampler is the uniform sampler without replacement which is implemented as org.yagnus.stats.samplers.Uniform, aka oy.USamp. This sampler keeps each object \"add()\"ed to it with probability percentage specified at construction time.\r\n\r\n    var sampler = oy.USamp(1.0); //keep one percent of everything \"add()\"ed\r\n    sampler.add(1);\r\n    sampler.add(2);\r\n    //... \r\n    sampler.calc();\r\n\r\nAll of our algorithms are natively parallel streaming distributed, and samplers are no exception. So one could do this and obtain the correct result without concern for the number of data points each of the sampler sees:\r\n\r\n    var s1 = oy.USamp(1.0); //takes percentage as parameter, so multiply all your ratios by 100.\r\n    var s2 = oy.USamp(1.0); //ahh, but the percentage must be the same for this to work.\r\n    //... distribute s1 and s2 to gather samples.\r\n    s1.inc(s2);\r\n    //s1 is now updated to include samples from both s1 and s2, as if the 1% sample is taken over the all the data.\r\n    s1.calc();\r\n\t\r\nUniform Reservoir Sampling\r\n----------------------------\r\nAnother popular style of sampling is reservoir sampling. This is the algorithm that takes uniformly at random a fixed number of samples from a fully apriori unknown but parallely fully observed population. Suppose we want to draw exact 15 winners from a big-data sized data points or a growing population, simply fire up a reservoir sampler and add away:\r\n\r\n    var sampler1 = oy.URsvr(15); //tell it how many we want to keep;\r\n    var sampler2 = oy.URsvr(15); //tell it how many we want to keep;\r\n    sampler1.add(1);\r\n    sampler2.add(2);\r\n    //... keep going\r\n\t sampler1.inc(sampler2);\r\n\t sampler1.calc();\r\n\r\nAnd we kept exactly 15 items selected completely at random.\r\n \r\nNon-uniform Reservoir Sampling\r\n----------------------------\r\nIt also happens sometimes that you will come to know the importance of a sample after you see it. We have a sampler that can sample in distributed parallel streams and maintain correct sampling probability. The importance is passed in as a weight on the second parameter of add. The total weight increases as more sample are added. There are two algorithms implemented to perform non-uniform sampler. They are named after the authors sucessfully describing the algorithm to yagnus: the Chao weighted reservoir sampler and the Efraimidis-Spirakis weighted reservoir sampler, aka CRsvr and ESRsvr\r\n\r\n    var sampler1 = oy.CRsvr(15); //tell it how many we want to keep;\r\n    var sampler2 = oy.CRsvr(15); //or oy.ESRsvr(15), but both must be the same implementation to merge.\r\n    sampler1.add(1,5);\r\n    sampler2.add(2,10000);\r\n    //... keep going\r\n\t sampler1.inc(sampler2);\r\n\t sampler1.calc();\r\n\r\nBecause inflation happens in almost any valued system, we provide a method to adjust for instentaneous inflation. This way we can provide inflation adjusted sample.\r\n    sampler.inflate(2); /// 2% inflation, \r\n\r\nThese non-uniform reservoir reservoir sampler is also knowns weighted reservoir sampler (WRS).\r\n\r\nInstallation\r\n======================\r\nMongoDb\r\n-----------------------\r\nOne can put it in the .mongorc.js\r\n\r\n    cat yagnus.js >> ~/.mongorc.js\r\n\r\nOr install it into system so that mapreduce can use the stats:\r\n\r\n    mongo localhost:27017/analytics yagnus.js oy_mongo_install.js\r\n\r\nAfter that, the stats observers can be used freely inside mapreduction:\r\n    db.rawData.mapReduce(\r\n\t\t  //map\r\n        function(){\r\n\t\t\t\temit(this.key, {us:[this.value1, this.value2, this.value3], ms:[[this.value1, this.value2, this.value3]], ds:[this.kw1,this.kw2]});\r\n        },\r\n\t\t  //reduce\r\n        function(k,vs){\r\n            var us = oy.UVar();\r\n            var ms = oy.MVar();\r\n            var ds = oy.DVar();\r\n            vs.forEach(function(v){\r\n                us.inc(v.us);\r\n                ms.inc(v.ms);\r\n                ds.inc(v.ds);\r\n            }\r\n            return {'us':us, 'ms':ms, 'vs':vs};\r\n        },\r\n        //options\r\n        {\r\n            finalize:  function(k,v){ /*v.us.calc();v.ms.calc();v.ds.calc() only if this table won't be reduced into again.*/ return v;},\r\n            out:       {reduce:  \"statistics_table\"},\r\n\t\t\t\tquery:      ord_date: { $gt: new Date('01/01/2012')},\r\n\t\t\t/* scope:   {'org':org, 'oy':oy'} only if these were not installed in system.js   */\r\n        }\r\n    );\r\n    \r\n    // one can also have the opposite situation where org and oy are not in ~/.mongorc.js but in system.js then one can load them before map-reducing.\r\n    var org=db.system.js.findOne({'_id':'org'}).value;\r\n    var oy=db.system.js.findOne({'_id':'oy'}).value;\r\n    \r\nAnd the statistics_table can be incrementally reduced into as needed.\r\nNote that system.js is stored for each database, so for every database mapreduce will run on, it must have it's own copy of this code installed unless you put org/oy into the scope manually at mapreduce time.\r\n\r\nnode.js\r\n-----------------------\r\nrequire(\"yagnus\");\r\n\r\n\r\nContributing\r\n============\r\nPlease, we'd love to have your algorithms. The project is co-hosted at two locations both on [github](https://github.com/alexia-b-chang/yag.js) and on [google code](https://code.google.com/p/yagnus/), check it out and send [me](mailto:alexia.b.chang@yagn.us) an email.\r\n\r\nYagnus.js Banner\r\n================\r\n                                                                          \r\n                                                                             ###\r\n                                                                             ###\r\n                                                                             ###\r\n                                                                           #####\r\n                                                                        ########\r\n                                                                    ############\r\n                                                                   #############\r\n                                                              ##################\r\n                                                            ####################\r\n                                                         ##################  ###\r\n                       ###                           ###################     ###\r\n                       ###                         ###################       ###\r\n                       ########################################### \r\n                       ######################################### \r\n                       ##################################### \r\n                       ##################################\r\n                       ################################\r\n                       ################################\r\n                       ###                        ####### \r\n                       ###                            ########\r\n                                                           ####### \r\n                                                            ########         ###\r\n                                                                 #######     ###\r\n                                                                     ###########\r\n                                                                        ########\r\n                                                                            ####\r\n                                                                             ###\r\n                                                                             ###\r\n                                                                             ###\r\n                                                                             ###\r\n                               #####\r\n                            ########## \r\n                          ###############        ###\r\n                         ################      #######\r\n                        ##################     ######## \r\n                       #####          #####    ######### \r\n                       ####            ####      ##  ####\r\n                       ####            ####           ###\r\n                       ####            ####           ###\r\n                        ###            ###            ###\r\n                         ###          ###           #####\r\n                          ###        ####         ###### \r\n                         ############################## \r\n                        ###############################\r\n                       ###############################\r\n                       ############################ \r\n                       ##########################\r\n                       ###\r\n                       ## \r\n                         \r\n            ######                       ####### \r\n          ##########                   ########### \r\n        #####      ###  ####        ################# \r\n       ####         ##########      ##################\r\n      ###             ##########  #####################\r\n     ####            ####################        ####### \r\n     ###             #########  ######             ##### \r\n     ###            ########    ####                  ###\r\n     ###           #########    ###                   ###\r\n     ###           ########     ###                   ###\r\n     ####         ########      ####                  ###\r\n     ####         ########      #####               #####\r\n     #####       ########        ########        ####### \r\n     ######     #########         ##################### \r\n      ##################           ####################\r\n        ###############             ################# #   ## \r\n         #############               ###############  ## #### \r\n            #######                      #######       #######\r\n                                                       #######\r\n                                                          ## \r\n                       ###                            ###\r\n                       ###                            ###\r\n                       ##################################\r\n                       ##################################\r\n                       ##################################\r\n                       ##################################\r\n                       ##################################\r\n                       ###                        ####\r\n                                                   ### \r\n                                                    ### \r\n                                                    #### \r\n                                                    #####\r\n                                                    #####\r\n                       ###                         ######\r\n                       ##################################\r\n                       ################################# \r\n                       ################################ \r\n                       ###############################\r\n                       #############################\r\n                       ###\r\n                          \r\n                                                      ###\r\n                                                      ###\r\n                            #############################\r\n                          ###############################\r\n                        #################################\r\n                        #################################\r\n                       ##################################\r\n                       ######\r\n                       ##### \r\n                       #### \r\n                        ### \r\n                        #### \r\n                          ###\r\n                          ###                         ###\r\n                       ##################################\r\n                       ##################################\r\n                       ##################################\r\n                       ##################################\r\n                       ##################################\r\n                       ###\r\n                          \r\n                       ########             ##### \r\n                       ########           ######### \r\n                       ########         ##############\r\n                         #####         ############### \r\n                        ####          ################# \r\n                        ###          #########        ## \r\n                       ###           ########         ###\r\n                       ###           ########         ###\r\n                       ###           #######          ###\r\n                       ###          ########          ###\r\n                       ###          ########         ### \r\n                       ###         #########        #### \r\n                        ###       #########        #### \r\n                        ###       ########        #####\r\n                         #################       ########\r\n                          ###############        ########\r\n                           ############# \r\n                               ######\r\n                                     \r\n                          ### \r\n                        #######\r\n                       #########\r\n                       #########\r\n                        ####### \r\n                          ### \r\n                              \r\n         ####\r\n       #######\r\n      ######## \r\n     ######### \r\n     ## ######\r\n     ## \r\n     ## \r\n     ###                                              ###\r\n     ####                                             ###          ### \r\n      ###################################################        ####### \r\n        #################################################       #########\r\n         ################################################       #########\r\n             ############################################        #######\r\n                #########################################          ### \r\n                       ########             ##### \r\n                       ########           ######### \r\n                       ########         ##############\r\n                         #####         ############### \r\n                        ####          ################# \r\n                        ###          #########        ## \r\n                       ###           ########         ###\r\n                       ###           ########         ###\r\n                       ###           #######          ###\r\n                       ###          ########          ###\r\n                       ###          ########         ### \r\n                       ###         #########        #### \r\n                        ###       #########        #### \r\n                        ###       ########        #####\r\n                         #################       ########\r\n                          ###############        ########\r\n                           ############# \r\n                               ######\r\n                                     \r\n                          ###                               ############ \r\n                        #######                   ######################### \r\n                       #########      ######################################## \r\n                       #########     ########################################## \r\n                        #######             ################################# \r\n                          ###                               ############ \r\n                                                                         \r\n                          ###                               ############ \r\n                        #######                   ######################### \r\n                       #########      ######################################## \r\n                       #########     ########################################## \r\n                        #######             ################################# \r\n                          ###                               ############ \r\n                                                                         \r\n\r\nFor Posterity\r\n======================\r\nDerivation of the Uniform Reservoir Sampling Scheme\r\n---------------------------------------------------\r\nOutline induction step: Suppose we were able to maintain a size k reservoir whose items are each inclded from n observations with probability k/n and that items not included in reservoir were given fair opportunity to be included with probability k/n. On observing a new item, we keep it with probability k/(n+1), this ensures that it's inclusion probability is k/(n+1). If it is decided to be included, it replaced an item chosen from existing size-k reservoir with probability 1/k. Thus we need to be assured that the items already in reservoir will, after this addition, be kept with probability k/(n+1).\r\n\r\nactually we can show that with what ever probability x/n any one item was kept in the reservoir before induction step, this replacement procedure will set it to x/(n+1). Starting with x/n, with probability (n+1-k)/(n+1) it is kept due to not including the new item; with probability k/(n+1) the new item is kept and it replaces the item of concern with probability 1/k, so the posterior probability, after add, of an existing reservoir item staying in the reservoir is:\r\n\r\n      x/n * (  (n+1-k)/(n+1) + (  k/(n+1) * (k-1)/k  )  )\r\n    = x/n * (nk+k-k^2+k^2-k)/(n+1)/k\r\n    = x/n * (nk)/(n+1)/k\r\n    = x/(n+1)\r\n\r\nfor any x, QED % base case. Originally described in \"Jeﬀrey Scott Vitter. Random sampling with a reservoir. ACM Transactions on Mathematical Software, 11(1):37–57, March 1985\", \"Donald E. Knuth. Seminumerical Algorithms, volume 2 of The Art of Computer Programming. Addison-Wesley, Reading, Mass., 2nd edition, 1981.\", etc\r\n\r\nDerivation of the M.T. Chao Weighted Reservoir Sampling Scheme:\r\n-----------------------------------------------------------\r\nMTChao reservoir sampling was originally described in \"M. T. Chao. A general purpose unequal probability sampling plan. Biometrika, 69(3):653–656, 1982.\", current author came to know it from [\"P. S. Efraimidis. Weighted Random Sampling over Data Streams, 2010\"](http://arxiv.org/pdf/1012.0256.pdf). Similar to the proof, esetablish basecase where each item i was kept with probability k*w_i, a new item n with weight w_n is introduced and kept with probability k*w_n. If the new item is kept, it replaces an item chosen uniformly at random from reservoir uniform. We need to maintain two accumulator variable, n being the sum of all weights seen so far and T, the sum of weights of items in the reservoir.\r\n\r\n        (k * w_i /n) * (  (n + n_w - k*w_n) / (n + w_n) + k * w_n/(n+w_n)  * (k-1)/k  )\r\n      =  k * w_i /n * (  (n + n_w - k*w_n) / (n + w_n) +  w_n/(n+w_n)  * (k-1)  )\r\n      =  k * w_i /n * (  (n + n_w - k*w_n) / (n + w_n) +  (k*w_n - w_n)/(n+w_n)  )\r\n      =  k * w_i /n * (  (n + n_w - k*w_n + k*w_n - w_n)/(n+w_n)  )\r\n      =  k * w_i /n * (  n/(n+w_n)  )\r\n      =  k * w_i / ( n + w_n )\r\n\r\nAwesome! But don't ask me on an interview question... it's going to take me just as long to rederive. This is why we have libraries, so it isn't rederived every single time.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}